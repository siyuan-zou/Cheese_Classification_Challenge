model:
  instance:
    _target_: models.dinov2.DinoV2Finetune
    num_classes: ${dataset.num_classes}
    frozen: true
    unfreeze_last_layer: true
  name: DINOV2
dataset:
  train_transform:
    _target_: torchvision.transforms.Compose
    transforms:
    - _target_: torchvision.transforms.RandomResizedCrop
      size: 224
    - _target_: torchvision.transforms.RandomHorizontalFlip
    - _target_: torchvision.transforms.ToTensor
    - _target_: torchvision.transforms.Normalize
      mean:
      - 0.485
      - 0.456
      - 0.406
      std:
      - 0.229
      - 0.224
      - 0.225
  test_transform:
    _target_: torchvision.transforms.Compose
    transforms:
    - _target_: torchvision.transforms.RandomResizedCrop
      size: 224
    - _target_: torchvision.transforms.RandomHorizontalFlip
    - _target_: torchvision.transforms.ToTensor
    - _target_: torchvision.transforms.Normalize
      mean:
      - 0.485
      - 0.456
      - 0.406
      std:
      - 0.229
      - 0.224
      - 0.225
  name: simple_pro_foods
  num_classes: 37
  batch_size: 128
  num_workers: 8
  train_path: ${data_dir}/train/simple_pro_foods
  real_images_val_path: ${data_dir}/val
  test_path: ${data_dir}/test
optim:
  _target_: torch.optim.AdamW
  lr: 0.001
  betas:
  - 0.9
  - 0.999
loss_fn:
  _partial_: true
  _target_: torch.nn.functional.cross_entropy
  reduction: mean
  label_smoothing: 0.05
epochs: 20
datamodule:
  _target_: data.datamodule.DataModule
  train_dataset_path: ${dataset.train_path}
  real_images_val_path: ${dataset.real_images_val_path}
  train_transform: ${dataset.train_transform}
  val_transform: ${dataset.test_transform}
  batch_size: ${dataset.batch_size}
  num_workers: ${dataset.num_workers}
data_dir: ${root_dir}/dataset
root_dir: ${hydra:runtime.cwd}
checkpoint_path: ${root_dir}/checkpoints/${experiment_name}.pt
experiment_name: ${model.name}_${dataset.name}
